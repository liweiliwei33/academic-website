@inproceedings{cao-etal-2022-explore,
    title = "Explore More Guidance: A Task-aware Instruction Network for Sign Language Translation Enhanced with Data Augmentation",
    author = "Cao, Yong  and
      Li, Wei  and
      Li, Xianzhi  and
      Chen, Min  and
      Chen, Guangyong  and
      Hu, Long  and
      Li, Zhengdao  and
      Hwang, Kai",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.205",
    doi = "10.18653/v1/2022.findings-naacl.205",
    pages = "2679--2690",
    abstract = "Sign language recognition and translation first uses a recognition module to generate glosses from sign language videos and then employs a translation module to translate glosses into spoken sentences. Most existing works focus on the recognition step, while paying less attention to sign language translation. In this work, we propose a task-aware instruction network, namely TIN-SLT, for sign language translation, by introducing the isntruction module and the learning-based feature fuse strategy into a Transformer network. In this way, the pre-trained model{'}s language ability can be well explored and utilized to further boost the translation performance. Moreover, by exploring the representation space of sign language glosses and target spoken language, we propose a multi-level data augmentation scheme to adjust the data distribution of the training set. We conduct extensive experiments on two challenging benchmark datasets, PHOENIX-2014-T and ASLG-PC12, on which our method outperforms former best solutions by 1.65 and 1.42 in terms of BLEU-4. Our code and trained networks will be available upon the publication of this work.",
}
