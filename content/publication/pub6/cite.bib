@InProceedings{10.1007/978-3-031-17120-8_5,
author="Jiang, Runmin
and Zhang, Xin
and Jiang, Jiyue
and Li, Wei
and Wang, Yuhao",
editor="Lu, Wei
and Huang, Shujian
and Hong, Yu
and Zhou, Xiabing",
title="How Effective and Robust is Sentence-Level Data Augmentation for Named Entity Recognition?",
booktitle="Natural Language Processing and Chinese Computing",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="55--66",
abstract="Data augmentation is a simple but effective way to improve the effectiveness and the robustness of pre-trained models. However, they are difficult to adapt to token-level tasks such as named entity recognition (NER) because of the different semantic granularity and more fine-grained labels. Inspired by some mixup augmentations in computer vision, we proposed three sentence-level data augmentations including CMix, CombiMix, TextMosaic, and adapted them to the NER task. Through empirical experiments on three authoritative datasets (OntoNotes4, CoNLL-03, OntoNotes5), we found that these methods will improve the effectiveness of the models if controlling the number of augmented samples. Strikingly, the results show our approaches can greatly improve the robustness of the pre-trained model even over strong baselines and token-level data augmentations. We achieved state-of-the-art (SOTA) in the robustness evaluation of the CCIR CUP 2021. The code is available at https://github.com/jrmjrm01/SenDA4NER-NLPCC2022.",
isbn="978-3-031-17120-8"
}
